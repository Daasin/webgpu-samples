_N_E=(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[21],{"7r7F":function(e,t,n){"use strict";n.r(t),n.d(t,"geometryVertexArray",(function(){return P}));var r,a,o=n("o0o1"),i=n.n(o),s=n("HaE+"),c=n("rePB"),u=n("IOcx"),d=n("SoUo");function p(e,t){var n;if("undefined"===typeof Symbol||null==e[Symbol.iterator]){if(Array.isArray(e)||(n=function(e,t){if(!e)return;if("string"===typeof e)return f(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);"Object"===n&&e.constructor&&(n=e.constructor.name);if("Map"===n||"Set"===n)return Array.from(e);if("Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n))return f(e,t)}(e))||t&&e&&"number"===typeof e.length){n&&(e=n);var r=0,a=function(){};return{s:a,n:function(){return r>=e.length?{done:!0}:{done:!1,value:e[r++]}},e:function(e){throw e},f:a}}throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}var o,i=!0,s=!1;return{s:function(){n=e[Symbol.iterator]()},n:function(){var e=n.next();return i=e.done,e},e:function(e){s=!0,o=e},f:function(){try{i||null==n.return||n.return()}finally{if(s)throw o}}}}function f(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}var l,m=32,h=12,v=1e-4,P=new Float32Array([-1.5,-1,v,1,1,0,0,1,.5,-1,v,1,1,0,0,1,-1.5,1,v,1,1,0,0,1,.5,-1,v,1,1,0,0,1,.5,1,v,1,1,0,0,1,-1.5,1,v,1,1,0,0,1,-.5,-1,-v,1,0,1,0,1,1.5,-1,-v,1,0,1,0,1,-.5,1,-v,1,0,1,0,1,1.5,-1,-v,1,0,1,0,1,1.5,1,-v,1,0,1,0,1,-.5,1,-v,1,0,1,0,1]),g=d.b/2,x=u.a.create();function b(e,t,n,r,a){var o=1/Math.tan(t/2);if(e[0]=o/n,e[1]=0,e[2]=0,e[3]=0,e[4]=0,e[5]=o,e[6]=0,e[7]=0,e[8]=0,e[9]=0,e[11]=-1,e[12]=0,e[13]=0,e[15]=0,null!=a&&a!==1/0){var i=1/(r-a);e[10]=a*i,e[14]=a*r*i}else e[10]=-1,e[14]=-r;return e}x[10]=-1,x[14]=1,function(e){e[e.Default=0]="Default",e[e.Reversed=1]="Reversed"}(l||(l={}));var y=[l.Default,l.Reversed],w=(r={},Object(c.a)(r,l.Default,"less"),Object(c.a)(r,l.Reversed,"greater"),r),D=(a={},Object(c.a)(a,l.Default,1),Object(c.a)(a,l.Reversed,0),a);function S(){return(S=Object(s.a)(i.a.mark((function e(t,n){var r,a,o,s,c,f,v,S,R,M,O,V,j,C,T,E,U,A,G,_,k,L,F,I,z,W,N,Q,q,H,$,Z,X,Y,J,K,ee,te,ne,re,ae,oe,ie,se;return i.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return ie=function(){for(var e=Date.now()/1e3,t=0,n=0;t<5;t++,n+=16)u.a.rotate(oe,q[t],Math.PI/180*30,u.b.fromValues(Math.sin(e),Math.cos(e),0)),H.set(oe,n)},e.next=3,navigator.gpu.requestAdapter();case 3:return r=e.sent,e.next=6,r.requestDevice();case 6:for(a=e.sent,o=t.getContext("webgpu"),s=window.devicePixelRatio||1,c=[t.clientWidth*s,t.clientHeight*s],f=o.getPreferredFormat(r),o.configure({device:a,format:f,size:c}),v=a.createBuffer({size:P.byteLength,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0}),new Float32Array(v.getMappedRange()).set(P),v.unmap(),S="depth32float",R={vertex:{module:a.createShaderModule({code:B.vertexDepthPrePass}),entryPoint:"main",buffers:[{arrayStride:m,attributes:[{shaderLocation:0,offset:0,format:"float32x4"}]}]},fragment:{module:a.createShaderModule({code:B.fragmentDepthPrePass}),entryPoint:"main",targets:[]},primitive:{topology:"triangle-list",cullMode:"back"},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:S}},M=[],R.depthStencil.depthCompare=w[l.Default],M[l.Default]=a.createRenderPipeline(R),R.depthStencil.depthCompare=w[l.Reversed],M[l.Reversed]=a.createRenderPipeline(R),O={vertex:{module:a.createShaderModule({code:B.vertexPrecisionErrorPass}),entryPoint:"main",buffers:[{arrayStride:m,attributes:[{shaderLocation:0,offset:0,format:"float32x4"}]}]},fragment:{module:a.createShaderModule({code:B.fragmentPrecisionErrorPass}),entryPoint:"main",targets:[{format:f}]},primitive:{topology:"triangle-list",cullMode:"back"},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:S}},V=[],O.depthStencil.depthCompare=w[l.Default],V[l.Default]=a.createRenderPipeline(O),O.depthStencil.depthCompare=w[l.Reversed],V[l.Reversed]=a.createRenderPipeline(O),j={vertex:{module:a.createShaderModule({code:B.vertex}),entryPoint:"main",buffers:[{arrayStride:m,attributes:[{shaderLocation:0,offset:0,format:"float32x4"},{shaderLocation:1,offset:16,format:"float32x4"}]}]},fragment:{module:a.createShaderModule({code:B.fragment}),entryPoint:"main",targets:[{format:f}]},primitive:{topology:"triangle-list",cullMode:"back"},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:S}},C=[],j.depthStencil.depthCompare=w[l.Default],C[l.Default]=a.createRenderPipeline(j),j.depthStencil.depthCompare=w[l.Reversed],C[l.Reversed]=a.createRenderPipeline(j),T=a.createRenderPipeline({vertex:{module:a.createShaderModule({code:B.vertexTextureQuad}),entryPoint:"main"},fragment:{module:a.createShaderModule({code:B.fragmentTextureQuad}),entryPoint:"main",targets:[{format:f}]},primitive:{topology:"triangle-list"}}),E=a.createTexture({size:c,format:S,usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.SAMPLED}),U=E.createView(),A=a.createTexture({size:c,format:S,usage:GPUTextureUsage.RENDER_ATTACHMENT}),G=A.createView(),_={colorAttachments:[],depthStencilAttachment:{view:U,depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}},k=[{colorAttachments:[{view:void 0,loadValue:{r:0,g:0,b:.5,a:1},storeOp:"store"}],depthStencilAttachment:{view:G,depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}},{colorAttachments:[{view:void 0,loadValue:"load",storeOp:"store"}],depthStencilAttachment:{view:G,depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}}],L=[{colorAttachments:[{view:void 0,loadValue:{r:0,g:0,b:.5,a:1},storeOp:"store"}]},{colorAttachments:[{view:void 0,loadValue:"load",storeOp:"store"}]}],F=a.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.FRAGMENT,texture:{sampleType:"float"}},{binding:1,visibility:GPUShaderStage.FRAGMENT,sampler:{type:"filtering"}}]}),I=a.createBindGroup({layout:F,entries:[{binding:0,resource:U},{binding:1,resource:a.createSampler()}]}),320,z=a.createBuffer({size:320,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),W=a.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),N=a.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),Q=[a.createBindGroup({layout:M[l.Default].getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:z}},{binding:1,resource:{buffer:W}}]}),a.createBindGroup({layout:M[l.Reversed].getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:z}},{binding:1,resource:{buffer:N}}]})],q=new Array(5),H=new Float32Array(80),$=0,Z=0;Z<1;Z++)for(X=0;X<5;X++)Y=-800*$,J=1+50*$,q[$]=u.a.create(),u.a.translate(q[$],q[$],u.b.fromValues(Z-.5+.5,(4-.2*Y)*(X-2.5+1),Y)),u.a.scale(q[$],q[$],u.b.fromValues(J,J,J)),$++;return K=u.a.create(),u.a.translate(K,K,u.b.fromValues(0,0,-12)),ee=.5*c[0]/c[1],b(te=u.a.create(),2*Math.PI/5,ee,5,1/0),ne=u.a.create(),u.a.multiply(ne,te,K),re=u.a.create(),u.a.multiply(re,x,ne),ae=ne,a.queue.writeBuffer(W,0,ae.buffer,ae.byteOffset,ae.byteLength),ae=re,a.queue.writeBuffer(N,0,ae.buffer,ae.byteOffset,ae.byteLength),oe=u.a.create(),se={mode:"color"},n.add(se,"mode",["color","precision-error","depth-texture"]),e.abrupt("return",(function(){ie(),a.queue.writeBuffer(z,0,H.buffer,H.byteOffset,H.byteLength);var e=o.getCurrentTexture().createView(),t=a.createCommandEncoder();if("color"===se.mode){var n,r=p(y);try{for(r.s();!(n=r.n()).done;){var i=n.value;k[i].colorAttachments[0].view=e,k[i].depthStencilAttachment.depthLoadValue=D[i];var c=t.beginRenderPass(k[i]);c.setPipeline(C[i]),c.setBindGroup(0,Q[i]),c.setVertexBuffer(0,v),c.setViewport(s*g*i,0,s*g,s*d.a,0,1),c.draw(h,5,0,0),c.endPass()}}catch(R){r.e(R)}finally{r.f()}}else if("precision-error"===se.mode){var u,f=p(y);try{for(f.s();!(u=f.n()).done;){var l=u.value;_.depthStencilAttachment.depthLoadValue=D[l];var m=t.beginRenderPass(_);m.setPipeline(M[l]),m.setBindGroup(0,Q[l]),m.setVertexBuffer(0,v),m.setViewport(s*g*l,0,s*g,s*d.a,0,1),m.draw(h,5,0,0),m.endPass(),k[l].colorAttachments[0].view=e,k[l].depthStencilAttachment.depthLoadValue=D[l];var P=t.beginRenderPass(k[l]);P.setPipeline(V[l]),P.setBindGroup(0,Q[l]),P.setBindGroup(1,I),P.setVertexBuffer(0,v),P.setViewport(s*g*l,0,s*g,s*d.a,0,1),P.draw(h,5,0,0),P.endPass()}}catch(R){f.e(R)}finally{f.f()}}else{var x,b=p(y);try{for(b.s();!(x=b.n()).done;){var w=x.value;_.depthStencilAttachment.depthLoadValue=D[w];var S=t.beginRenderPass(_);S.setPipeline(M[w]),S.setBindGroup(0,Q[w]),S.setVertexBuffer(0,v),S.setViewport(s*g*w,0,s*g,s*d.a,0,1),S.draw(h,5,0,0),S.endPass(),L[w].colorAttachments[0].view=e;var B=t.beginRenderPass(L[w]);B.setPipeline(T),B.setBindGroup(0,I),B.setViewport(s*g*w,0,s*g,s*d.a,0,1),B.draw(6,1,0,0),B.endPass()}}catch(R){b.e(R)}finally{b.f()}}a.queue.submit([t.finish()])}));case 74:case"end":return e.stop()}}),e)})))).apply(this,arguments)}var B={vertex:"\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(".concat(64,")]] array<mat4x4<f32>, ").concat(5,">;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\nstruct VertexOutput {\n  [[builtin(position)]] Position : vec4<f32>;\n  [[location(0)]] fragColor : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>,\n        [[location(1)]] color : vec4<f32>) -> VertexOutput {\n  var output : VertexOutput;\n  output.Position = camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n  output.fragColor = color;\n  return output;\n}\n"),fragment:"\n[[stage(fragment)]]\nfn main([[location(0)]] fragColor : vec4<f32>) -> [[location(0)]] vec4<f32> {\n  return fragColor;\n}\n",vertexDepthPrePass:"\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(".concat(64,")]] array<mat4x4<f32>, ").concat(5,">;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>)\n     -> [[builtin(position)]] vec4<f32> {\n  return camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n}\n"),fragmentDepthPrePass:"\n[[stage(fragment)]]\nfn main() {\n}\n",vertexPrecisionErrorPass:"\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(".concat(64,")]] array<mat4x4<f32>, ").concat(5,">;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\nstruct VertexOutput {\n  [[builtin(position)]] Position : vec4<f32>;\n  [[location(0)]] clipPos : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>) -> VertexOutput {\n  var output : VertexOutput;\n  output.Position = camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n  output.clipPos = output.Position;\n  return output;\n}\n"),fragmentPrecisionErrorPass:"\n[[group(1), binding(0)]] var depthTexture: texture_2d<f32>;\n[[group(1), binding(1)]] var depthSampler: sampler;\n\n[[stage(fragment)]]\nfn main([[builtin(position)]] coord : vec4<f32>,\n        [[location(0)]] clipPos : vec4<f32>)\n     -> [[location(0)]] vec4<f32> {\n  let depthValue : f32 = textureSample(depthTexture, depthSampler, coord.xy / vec2<f32>(".concat(d.b.toFixed(1),", ").concat(d.a.toFixed(1),")).r;\n  let v : f32 = abs(clipPos.z / clipPos.w - depthValue) * 2000000.0;\n  return vec4<f32>(v, v, v, 1.0) ;\n}\n"),vertexTextureQuad:"\n[[stage(vertex)]]\nfn main([[builtin(vertex_index)]] VertexIndex : u32)\n     -> [[builtin(position)]] vec4<f32> {\n  var pos : array<vec2<f32>, 6> = array<vec2<f32>, 6>(\n    vec2<f32>(-1.0, -1.0), vec2<f32>(1.0, -1.0), vec2<f32>(-1.0, 1.0),\n    vec2<f32>(-1.0, 1.0), vec2<f32>(1.0, -1.0), vec2<f32>(1.0, 1.0));\n\n  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);\n}\n",fragmentTextureQuad:"\n[[group(0), binding(0)]] var depthTexture: texture_2d<f32>;\n[[group(0), binding(1)]] var depthSampler: sampler;\n\n[[stage(fragment)]]\nfn main([[builtin(position)]] coord : vec4<f32>)\n     -> [[location(0)]] vec4<f32> {\n  let depthValue : f32 = textureSample(depthTexture, depthSampler, coord.xy / vec2<f32>(".concat(d.b.toFixed(1),", ").concat(d.a.toFixed(1),")).r;\n  return vec4<f32>(depthValue, depthValue, depthValue, 1.0);\n}\n")};t.default=Object(d.c)({name:"Reversed Z",description:"This example shows the use of reversed z technique for better utilization of depth buffer precision.\n    The left column uses regular method, while the right one uses reversed z technique.\n    Both are using depth32float as their depth buffer format. A set of red and green planes are positioned very close to each other.\n    Higher sets are placed further from camera (and are scaled for better visual purpose).\n    To use reversed z to render your scene, you will need depth store value to be 0.0, depth compare function to be greater,\n    and remap depth range by multiplying an additional matrix to your projection matrix.\n    Related reading:\n    https://developer.nvidia.com/content/depth-precision-visualized\n    https://thxforthefish.com/posts/reverse_z/\n    ",slug:"reversedZ",init:function(e,t){return S.apply(this,arguments)},source:"import { mat4, vec3 } from 'gl-matrix';\nimport type { GUI } from 'dat.gui';\nimport {\n  kDefaultCanvasWidth,\n  kDefaultCanvasHeight,\n  makeBasicExample,\n} from '../../components/basicExample';\n\n// Two planes close to each other for depth precision test\nconst geometryVertexSize = 4 * 8; // Byte size of one geometry vertex.\nconst geometryPositionOffset = 0;\nconst geometryColorOffset = 4 * 4; // Byte offset of geometry vertex color attribute.\nconst geometryDrawCount = 6 * 2;\n\nconst d = 0.0001; // half distance between two planes\nconst o = 0.5; // half x offset to shift planes so they are only partially overlaping\n\n// prettier-ignore\nexport const geometryVertexArray = new Float32Array([\n  // float4 position, float4 color\n  -1 - o, -1, d, 1, 1, 0, 0, 1,\n   1 - o, -1, d, 1,  1, 0, 0, 1,\n  -1 - o, 1, d, 1,  1, 0, 0, 1,\n   1 - o, -1,  d, 1, 1, 0, 0, 1,\n   1 - o, 1,  d, 1,  1, 0, 0, 1,\n  -1 - o, 1, d, 1,  1, 0, 0, 1,\n\n  -1 + o, -1, -d, 1, 0, 1, 0, 1,\n   1 + o, -1, -d, 1,  0, 1, 0, 1,\n  -1 + o, 1, -d, 1,  0, 1, 0, 1,\n   1 + o, -1,  -d, 1, 0, 1, 0, 1,\n   1 + o, 1,  -d, 1,  0, 1, 0, 1,\n  -1 + o, 1, -d, 1,  0, 1, 0, 1,\n]);\n\nconst kViewportWidth = kDefaultCanvasWidth / 2;\n\nconst xCount = 1;\nconst yCount = 5;\nconst numInstances = xCount * yCount;\nconst matrixFloatCount = 16; // 4x4 matrix\nconst matrixStride = 4 * matrixFloatCount;\n\nconst depthRangeRemapMatrix = mat4.create();\ndepthRangeRemapMatrix[10] = -1;\ndepthRangeRemapMatrix[14] = 1;\n\n// https://github.com/toji/gl-matrix/commit/e906eb7bb02822a81b1d197c6b5b33563c0403c0\nfunction perspectiveZO(out, fovy, aspect, near, far) {\n  const f = 1.0 / Math.tan(fovy / 2);\n  out[0] = f / aspect;\n  out[1] = 0;\n  out[2] = 0;\n  out[3] = 0;\n  out[4] = 0;\n  out[5] = f;\n  out[6] = 0;\n  out[7] = 0;\n  out[8] = 0;\n  out[9] = 0;\n  out[11] = -1;\n  out[12] = 0;\n  out[13] = 0;\n  out[15] = 0;\n  if (far != null && far !== Infinity) {\n    const nf = 1 / (near - far);\n    out[10] = far * nf;\n    out[14] = far * near * nf;\n  } else {\n    out[10] = -1;\n    out[14] = -near;\n  }\n  return out;\n}\n\nenum DepthBufferMode {\n  Default = 0,\n  Reversed,\n}\n\nconst depthBufferModes: DepthBufferMode[] = [\n  DepthBufferMode.Default,\n  DepthBufferMode.Reversed,\n];\nconst depthCompareFuncs = {\n  [DepthBufferMode.Default]: 'less' as GPUCompareFunction,\n  [DepthBufferMode.Reversed]: 'greater' as GPUCompareFunction,\n};\nconst depthLoadValues = {\n  [DepthBufferMode.Default]: 1.0,\n  [DepthBufferMode.Reversed]: 0.0,\n};\n\nasync function init(canvas: HTMLCanvasElement, gui?: GUI) {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  const context = canvas.getContext('webgpu');\n\n  const devicePixelRatio = window.devicePixelRatio || 1;\n  const presentationSize = [\n    canvas.clientWidth * devicePixelRatio,\n    canvas.clientHeight * devicePixelRatio,\n  ];\n  const presentationFormat = context.getPreferredFormat(adapter);\n\n  context.configure({\n    device,\n    format: presentationFormat,\n    size: presentationSize,\n  });\n\n  const verticesBuffer = device.createBuffer({\n    size: geometryVertexArray.byteLength,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  new Float32Array(verticesBuffer.getMappedRange()).set(geometryVertexArray);\n  verticesBuffer.unmap();\n\n  const depthBufferFormat = 'depth32float';\n\n  // depthPrePass is used to render scene to the depth texture\n  // this is not needed if you just want to use reversed z to render a scene\n  const depthPrePassRenderPipelineDescriptorBase: GPURenderPipelineDescriptor = {\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertexDepthPrePass,\n      }),\n      entryPoint: 'main',\n      buffers: [\n        {\n          arrayStride: geometryVertexSize,\n          attributes: [\n            {\n              // position\n              shaderLocation: 0,\n              offset: geometryPositionOffset,\n              format: 'float32x4',\n            },\n          ],\n        },\n      ],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: wgslShaders.fragmentDepthPrePass,\n      }),\n      entryPoint: 'main',\n      targets: [],\n    },\n    primitive: {\n      topology: 'triangle-list',\n      cullMode: 'back',\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: depthBufferFormat,\n    },\n  };\n  // we need the depthCompare to fit the depth buffer mode we are using.\n  // this is the same for other passes\n  const depthPrePassPipelines: GPURenderPipeline[] = [];\n  depthPrePassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Default];\n  depthPrePassPipelines[DepthBufferMode.Default] = device.createRenderPipeline(\n    depthPrePassRenderPipelineDescriptorBase\n  );\n  depthPrePassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Reversed];\n  depthPrePassPipelines[DepthBufferMode.Reversed] = device.createRenderPipeline(\n    depthPrePassRenderPipelineDescriptorBase\n  );\n\n  // precisionPass is to draw precision error as color of depth value stored in depth buffer\n  // compared to that directly calcualated in the shader\n  const precisionPassRenderPipelineDescriptorBase: GPURenderPipelineDescriptor = {\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertexPrecisionErrorPass,\n      }),\n      entryPoint: 'main',\n      buffers: [\n        {\n          arrayStride: geometryVertexSize,\n          attributes: [\n            {\n              // position\n              shaderLocation: 0,\n              offset: geometryPositionOffset,\n              format: 'float32x4',\n            },\n          ],\n        },\n      ],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: wgslShaders.fragmentPrecisionErrorPass,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'triangle-list',\n      cullMode: 'back',\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: depthBufferFormat,\n    },\n  };\n  const precisionPassPipelines: GPURenderPipeline[] = [];\n  precisionPassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Default];\n  precisionPassPipelines[DepthBufferMode.Default] = device.createRenderPipeline(\n    precisionPassRenderPipelineDescriptorBase\n  );\n  precisionPassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Reversed];\n  precisionPassPipelines[\n    DepthBufferMode.Reversed\n  ] = device.createRenderPipeline(precisionPassRenderPipelineDescriptorBase);\n\n  // colorPass is the regular render pass to render the scene\n  const colorPassRenderPipelineDescriptorBase: GPURenderPipelineDescriptor = {\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertex,\n      }),\n      entryPoint: 'main',\n      buffers: [\n        {\n          arrayStride: geometryVertexSize,\n          attributes: [\n            {\n              // position\n              shaderLocation: 0,\n              offset: geometryPositionOffset,\n              format: 'float32x4',\n            },\n            {\n              // color\n              shaderLocation: 1,\n              offset: geometryColorOffset,\n              format: 'float32x4',\n            },\n          ],\n        },\n      ],\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: wgslShaders.fragment,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'triangle-list',\n      cullMode: 'back',\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: depthBufferFormat,\n    },\n  };\n  const colorPassPipelines: GPURenderPipeline[] = [];\n  colorPassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Default];\n  colorPassPipelines[DepthBufferMode.Default] = device.createRenderPipeline(\n    colorPassRenderPipelineDescriptorBase\n  );\n  colorPassRenderPipelineDescriptorBase.depthStencil.depthCompare =\n    depthCompareFuncs[DepthBufferMode.Reversed];\n  colorPassPipelines[DepthBufferMode.Reversed] = device.createRenderPipeline(\n    colorPassRenderPipelineDescriptorBase\n  );\n\n  // textureQuadPass is draw a full screen quad of depth texture\n  // to see the difference of depth value using reversed z compared to default depth buffer usage\n  // 0.0 will be the furthest and 1.0 will be the closest\n  const textureQuadPassPipline = device.createRenderPipeline({\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertexTextureQuad,\n      }),\n      entryPoint: 'main',\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: wgslShaders.fragmentTextureQuad,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: presentationFormat,\n        },\n      ],\n    },\n    primitive: {\n      topology: 'triangle-list',\n    },\n  });\n\n  const depthTexture = device.createTexture({\n    size: presentationSize,\n    format: depthBufferFormat,\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.SAMPLED,\n  });\n  const depthTextureView = depthTexture.createView();\n\n  const defaultDepthTexture = device.createTexture({\n    size: presentationSize,\n    format: depthBufferFormat,\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n  const defaultDepthTextureView = defaultDepthTexture.createView();\n\n  const depthPrePassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [],\n    depthStencilAttachment: {\n      view: depthTextureView,\n\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0,\n      stencilStoreOp: 'store',\n    },\n  };\n\n  // drawPassDescriptor and drawPassLoadDescriptor are used for drawing\n  // the scene twice using different depth buffer mode on splitted viewport\n  // of the same canvas\n  // see the difference of the loadValue of the colorAttachments\n  const drawPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        loadValue: { r: 0.0, g: 0.0, b: 0.5, a: 1.0 },\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: defaultDepthTextureView,\n\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0.0,\n      stencilStoreOp: 'store',\n    },\n  };\n  const drawPassLoadDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // attachment is acquired and set in render loop.\n        view: undefined,\n\n        loadValue: 'load',\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: defaultDepthTextureView,\n\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0.0,\n      stencilStoreOp: 'store',\n    },\n  };\n  const drawPassDescriptors = [drawPassDescriptor, drawPassLoadDescriptor];\n\n  const textureQuadPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        loadValue: { r: 0.0, g: 0.0, b: 0.5, a: 1.0 },\n        storeOp: 'store',\n      },\n    ],\n  };\n  const textureQuadPassLoadDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        loadValue: 'load',\n        storeOp: 'store',\n      },\n    ],\n  };\n  const textureQuadPassDescriptors = [\n    textureQuadPassDescriptor,\n    textureQuadPassLoadDescriptor,\n  ];\n\n  const depthTextureBindGroupLayout = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'float',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.FRAGMENT,\n        sampler: {\n          type: 'filtering',\n        },\n      },\n    ],\n  });\n  const depthTextureBindGroup = device.createBindGroup({\n    layout: depthTextureBindGroupLayout,\n    entries: [\n      {\n        binding: 0,\n        resource: depthTextureView,\n      },\n      {\n        binding: 1,\n        resource: device.createSampler(),\n      },\n    ],\n  });\n\n  const uniformBufferSize = numInstances * matrixStride;\n\n  const uniformBuffer = device.createBuffer({\n    size: uniformBufferSize,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  const cameraMatrixBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n  const cameraMatrixReversedDepthBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const uniformBindGroups = [\n    device.createBindGroup({\n      layout: depthPrePassPipelines[DepthBufferMode.Default].getBindGroupLayout(\n        0\n      ),\n      entries: [\n        {\n          binding: 0,\n          resource: {\n            buffer: uniformBuffer,\n          },\n        },\n        {\n          binding: 1,\n          resource: {\n            buffer: cameraMatrixBuffer,\n          },\n        },\n      ],\n    }),\n    device.createBindGroup({\n      layout: depthPrePassPipelines[\n        DepthBufferMode.Reversed\n      ].getBindGroupLayout(0),\n      entries: [\n        {\n          binding: 0,\n          resource: {\n            buffer: uniformBuffer,\n          },\n        },\n        {\n          binding: 1,\n          resource: {\n            buffer: cameraMatrixReversedDepthBuffer,\n          },\n        },\n      ],\n    }),\n  ];\n\n  const modelMatrices = new Array(numInstances);\n  const mvpMatricesData = new Float32Array(matrixFloatCount * numInstances);\n\n  let m = 0;\n  for (let x = 0; x < xCount; x++) {\n    for (let y = 0; y < yCount; y++) {\n      const z = -800 * m;\n      const s = 1 + 50 * m;\n\n      modelMatrices[m] = mat4.create();\n\n      mat4.translate(\n        modelMatrices[m],\n        modelMatrices[m],\n        vec3.fromValues(\n          x - xCount / 2 + 0.5,\n          (4.0 - 0.2 * z) * (y - yCount / 2 + 1.0),\n          z\n        )\n      );\n      mat4.scale(modelMatrices[m], modelMatrices[m], vec3.fromValues(s, s, s));\n\n      m++;\n    }\n  }\n\n  const viewMatrix = mat4.create();\n  mat4.translate(viewMatrix, viewMatrix, vec3.fromValues(0, 0, -12));\n\n  const aspect = (0.5 * presentationSize[0]) / presentationSize[1];\n  const projectionMatrix = mat4.create();\n  perspectiveZO(projectionMatrix, (2 * Math.PI) / 5, aspect, 5, Infinity);\n\n  const viewProjectionMatrix = mat4.create();\n  mat4.multiply(viewProjectionMatrix, projectionMatrix, viewMatrix);\n  const reversedRangeViewProjectionMatrix = mat4.create();\n  // to use 1/z we just multiple depthRangeRemapMatrix to our default camera view projection matrix\n  mat4.multiply(\n    reversedRangeViewProjectionMatrix,\n    depthRangeRemapMatrix,\n    viewProjectionMatrix\n  );\n\n  let bufferData = viewProjectionMatrix as Float32Array;\n  device.queue.writeBuffer(\n    cameraMatrixBuffer,\n    0,\n    bufferData.buffer,\n    bufferData.byteOffset,\n    bufferData.byteLength\n  );\n  bufferData = reversedRangeViewProjectionMatrix as Float32Array;\n  device.queue.writeBuffer(\n    cameraMatrixReversedDepthBuffer,\n    0,\n    bufferData.buffer,\n    bufferData.byteOffset,\n    bufferData.byteLength\n  );\n\n  const tmpMat4 = mat4.create();\n  function updateTransformationMatrix() {\n    const now = Date.now() / 1000;\n\n    for (let i = 0, m = 0; i < numInstances; i++, m += matrixFloatCount) {\n      mat4.rotate(\n        tmpMat4,\n        modelMatrices[i],\n        (Math.PI / 180) * 30,\n        vec3.fromValues(Math.sin(now), Math.cos(now), 0)\n      );\n      mvpMatricesData.set(tmpMat4, m);\n    }\n  }\n\n  const settings = {\n    mode: 'color',\n  };\n  gui.add(settings, 'mode', ['color', 'precision-error', 'depth-texture']);\n\n  return function frame() {\n    updateTransformationMatrix();\n    device.queue.writeBuffer(\n      uniformBuffer,\n      0,\n      mvpMatricesData.buffer,\n      mvpMatricesData.byteOffset,\n      mvpMatricesData.byteLength\n    );\n\n    const attachment = context.getCurrentTexture().createView();\n    const commandEncoder = device.createCommandEncoder();\n    if (settings.mode === 'color') {\n      for (const m of depthBufferModes) {\n        drawPassDescriptors[m].colorAttachments[0].view = attachment;\n        drawPassDescriptors[m].depthStencilAttachment.depthLoadValue =\n          depthLoadValues[m];\n        const colorPass = commandEncoder.beginRenderPass(\n          drawPassDescriptors[m]\n        );\n        colorPass.setPipeline(colorPassPipelines[m]);\n        colorPass.setBindGroup(0, uniformBindGroups[m]);\n        colorPass.setVertexBuffer(0, verticesBuffer);\n        colorPass.setViewport(\n          devicePixelRatio * kViewportWidth * m,\n          0,\n          devicePixelRatio * kViewportWidth,\n          devicePixelRatio * kDefaultCanvasHeight,\n          0,\n          1\n        );\n        colorPass.draw(geometryDrawCount, numInstances, 0, 0);\n        colorPass.endPass();\n      }\n    } else if (settings.mode === 'precision-error') {\n      for (const m of depthBufferModes) {\n        {\n          depthPrePassDescriptor.depthStencilAttachment.depthLoadValue =\n            depthLoadValues[m];\n          const depthPrePass = commandEncoder.beginRenderPass(\n            depthPrePassDescriptor\n          );\n          depthPrePass.setPipeline(depthPrePassPipelines[m]);\n          depthPrePass.setBindGroup(0, uniformBindGroups[m]);\n          depthPrePass.setVertexBuffer(0, verticesBuffer);\n          depthPrePass.setViewport(\n            devicePixelRatio * kViewportWidth * m,\n            0,\n            devicePixelRatio * kViewportWidth,\n            devicePixelRatio * kDefaultCanvasHeight,\n            0,\n            1\n          );\n          depthPrePass.draw(geometryDrawCount, numInstances, 0, 0);\n          depthPrePass.endPass();\n        }\n        {\n          drawPassDescriptors[m].colorAttachments[0].view = attachment;\n          drawPassDescriptors[m].depthStencilAttachment.depthLoadValue =\n            depthLoadValues[m];\n          const precisionErrorPass = commandEncoder.beginRenderPass(\n            drawPassDescriptors[m]\n          );\n          precisionErrorPass.setPipeline(precisionPassPipelines[m]);\n          precisionErrorPass.setBindGroup(0, uniformBindGroups[m]);\n          precisionErrorPass.setBindGroup(1, depthTextureBindGroup);\n          precisionErrorPass.setVertexBuffer(0, verticesBuffer);\n          precisionErrorPass.setViewport(\n            devicePixelRatio * kViewportWidth * m,\n            0,\n            devicePixelRatio * kViewportWidth,\n            devicePixelRatio * kDefaultCanvasHeight,\n            0,\n            1\n          );\n          precisionErrorPass.draw(geometryDrawCount, numInstances, 0, 0);\n          precisionErrorPass.endPass();\n        }\n      }\n    } else {\n      // depth texture quad\n      for (const m of depthBufferModes) {\n        {\n          depthPrePassDescriptor.depthStencilAttachment.depthLoadValue =\n            depthLoadValues[m];\n          const depthPrePass = commandEncoder.beginRenderPass(\n            depthPrePassDescriptor\n          );\n          depthPrePass.setPipeline(depthPrePassPipelines[m]);\n          depthPrePass.setBindGroup(0, uniformBindGroups[m]);\n          depthPrePass.setVertexBuffer(0, verticesBuffer);\n          depthPrePass.setViewport(\n            devicePixelRatio * kViewportWidth * m,\n            0,\n            devicePixelRatio * kViewportWidth,\n            devicePixelRatio * kDefaultCanvasHeight,\n            0,\n            1\n          );\n          depthPrePass.draw(geometryDrawCount, numInstances, 0, 0);\n          depthPrePass.endPass();\n        }\n        {\n          textureQuadPassDescriptors[m].colorAttachments[0].view = attachment;\n          const depthTextureQuadPass = commandEncoder.beginRenderPass(\n            textureQuadPassDescriptors[m]\n          );\n          depthTextureQuadPass.setPipeline(textureQuadPassPipline);\n          depthTextureQuadPass.setBindGroup(0, depthTextureBindGroup);\n          depthTextureQuadPass.setViewport(\n            devicePixelRatio * kViewportWidth * m,\n            0,\n            devicePixelRatio * kViewportWidth,\n            devicePixelRatio * kDefaultCanvasHeight,\n            0,\n            1\n          );\n          depthTextureQuadPass.draw(6, 1, 0, 0);\n          depthTextureQuadPass.endPass();\n        }\n      }\n    }\n    device.queue.submit([commandEncoder.finish()]);\n  };\n}\n\nconst wgslShaders = {\n  vertex: `\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(${matrixStride})]] array<mat4x4<f32>, ${numInstances}>;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\nstruct VertexOutput {\n  [[builtin(position)]] Position : vec4<f32>;\n  [[location(0)]] fragColor : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>,\n        [[location(1)]] color : vec4<f32>) -> VertexOutput {\n  var output : VertexOutput;\n  output.Position = camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n  output.fragColor = color;\n  return output;\n}\n`,\n  fragment: `\n[[stage(fragment)]]\nfn main([[location(0)]] fragColor : vec4<f32>) -> [[location(0)]] vec4<f32> {\n  return fragColor;\n}\n`,\n  vertexDepthPrePass: `\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(${matrixStride})]] array<mat4x4<f32>, ${numInstances}>;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>)\n     -> [[builtin(position)]] vec4<f32> {\n  return camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n}\n`,\n  fragmentDepthPrePass: `\n[[stage(fragment)]]\nfn main() {\n}\n`,\n  vertexPrecisionErrorPass: `\n[[block]] struct Uniforms {\n  modelMatrix : [[stride(${matrixStride})]] array<mat4x4<f32>, ${numInstances}>;\n};\n[[block]] struct Camera {\n  viewProjectionMatrix : mat4x4<f32>;\n};\n\n[[binding(0), group(0)]] var<uniform> uniforms : Uniforms;\n[[binding(1), group(0)]] var<uniform> camera : Camera;\n\nstruct VertexOutput {\n  [[builtin(position)]] Position : vec4<f32>;\n  [[location(0)]] clipPos : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[builtin(instance_index)]] instanceIdx : u32,\n        [[location(0)]] position : vec4<f32>) -> VertexOutput {\n  var output : VertexOutput;\n  output.Position = camera.viewProjectionMatrix * uniforms.modelMatrix[instanceIdx] * position;\n  output.clipPos = output.Position;\n  return output;\n}\n`,\n  fragmentPrecisionErrorPass: `\n[[group(1), binding(0)]] var depthTexture: texture_2d<f32>;\n[[group(1), binding(1)]] var depthSampler: sampler;\n\n[[stage(fragment)]]\nfn main([[builtin(position)]] coord : vec4<f32>,\n        [[location(0)]] clipPos : vec4<f32>)\n     -> [[location(0)]] vec4<f32> {\n  let depthValue : f32 = textureSample(depthTexture, depthSampler, coord.xy / vec2<f32>(${kDefaultCanvasWidth.toFixed(\n    1\n  )}, ${kDefaultCanvasHeight.toFixed(1)})).r;\n  let v : f32 = abs(clipPos.z / clipPos.w - depthValue) * 2000000.0;\n  return vec4<f32>(v, v, v, 1.0) ;\n}\n`,\n  vertexTextureQuad: `\n[[stage(vertex)]]\nfn main([[builtin(vertex_index)]] VertexIndex : u32)\n     -> [[builtin(position)]] vec4<f32> {\n  var pos : array<vec2<f32>, 6> = array<vec2<f32>, 6>(\n    vec2<f32>(-1.0, -1.0), vec2<f32>(1.0, -1.0), vec2<f32>(-1.0, 1.0),\n    vec2<f32>(-1.0, 1.0), vec2<f32>(1.0, -1.0), vec2<f32>(1.0, 1.0));\n\n  return vec4<f32>(pos[VertexIndex], 0.0, 1.0);\n}\n`,\n  fragmentTextureQuad: `\n[[group(0), binding(0)]] var depthTexture: texture_2d<f32>;\n[[group(0), binding(1)]] var depthSampler: sampler;\n\n[[stage(fragment)]]\nfn main([[builtin(position)]] coord : vec4<f32>)\n     -> [[location(0)]] vec4<f32> {\n  let depthValue : f32 = textureSample(depthTexture, depthSampler, coord.xy / vec2<f32>(${kDefaultCanvasWidth.toFixed(\n    1\n  )}, ${kDefaultCanvasHeight.toFixed(1)})).r;\n  return vec4<f32>(depthValue, depthValue, depthValue, 1.0);\n}\n`,\n};\n\nexport default makeBasicExample({\n  name: 'Reversed Z',\n  description: `This example shows the use of reversed z technique for better utilization of depth buffer precision.\n    The left column uses regular method, while the right one uses reversed z technique.\n    Both are using depth32float as their depth buffer format. A set of red and green planes are positioned very close to each other.\n    Higher sets are placed further from camera (and are scaled for better visual purpose).\n    To use reversed z to render your scene, you will need depth store value to be 0.0, depth compare function to be greater,\n    and remap depth range by multiplying an additional matrix to your projection matrix.\n    Related reading:\n    https://developer.nvidia.com/content/depth-precision-visualized\n    https://thxforthefish.com/posts/reverse_z/\n    `,\n  slug: 'reversedZ',\n  init,\n  source: __SOURCE__,\n  gui: true,\n});\n",gui:!0})},BsWD:function(e,t,n){"use strict";n.d(t,"a",(function(){return a}));var r=n("a3WO");function a(e,t){if(e){if("string"===typeof e)return Object(r.a)(e,t);var n=Object.prototype.toString.call(e).slice(8,-1);return"Object"===n&&e.constructor&&(n=e.constructor.name),"Map"===n||"Set"===n?Array.from(e):"Arguments"===n||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)?Object(r.a)(e,t):void 0}}},O1S9:function(e,t,n){e.exports={shaderEditor:"BasicExample_shaderEditor__2wVi1",updateShaderBtn:"BasicExample_updateShaderBtn__Qgygo",canvasContainer:"BasicExample_canvasContainer__3e5KH"}},SoUo:function(e,t,n){"use strict";n.d(t,"b",(function(){return O})),n.d(t,"a",(function(){return V})),n.d(t,"c",(function(){return E}));var r=n("a3WO");var a=n("BsWD");function o(e){return function(e){if(Array.isArray(e))return Object(r.a)(e)}(e)||function(e){if("undefined"!==typeof Symbol&&Symbol.iterator in Object(e))return Array.from(e)}(e)||Object(a.a)(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var i=n("nKUr");function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=n("o0o1"),u=n.n(c),d=n("HaE+");function p(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}function f(e,t){for(var n=0;n<t.length;n++){var r=t[n];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(e,r.key,r)}}function l(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function m(e,t){return(m=Object.setPrototypeOf||function(e,t){return e.__proto__=t,e})(e,t)}function h(e){return(h="function"===typeof Symbol&&"symbol"===typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"===typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e})(e)}function v(e,t){return!t||"object"!==h(t)&&"function"!==typeof t?l(e):t}function P(e){return(P=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)})(e)}var g=n("rePB"),x=n("g4pe"),b=n.n(x),y=n("q1tI"),w=n.n(y),D=n("O1S9"),S=n.n(D);function B(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function R(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?B(Object(n),!0).forEach((function(t){Object(g.a)(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):B(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function M(e){var t=function(){if("undefined"===typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"===typeof Proxy)return!0;try{return Date.prototype.toString.call(Reflect.construct(Date,[],(function(){}))),!0}catch(e){return!1}}();return function(){var n,r=P(e);if(t){var a=P(this).constructor;n=Reflect.construct(r,arguments,a)}else n=r.apply(this,arguments);return v(this,n)}}var O=600,V=600;n("+dQi");var j=n("VrN/"),C=n("7QzT").setShaderRegisteredCallback,T=function(e){!function(e,t){if("function"!==typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),t&&m(e,t)}(c,e);var t,r,a,o=M(c);function c(){var e;p(this,c);for(var t=arguments.length,n=new Array(t),r=0;r<t;r++)n[r]=arguments[r];return e=o.call.apply(o,[this].concat(n)),Object(g.a)(l(e),"stopRunning",!1),Object(g.a)(l(e),"canvasRef",w.a.createRef()),e}return t=c,(r=[{key:"componentDidMount",value:function(){var e=this,t=void 0;this.props.gui&&(t=new(n("iZKT").GUI)({autoPlace:!1}),this.canvasRef.current.parentNode.appendChild(t.domElement),t.domElement.style.position="absolute",t.domElement.style.top="10px",t.domElement.style.right="10px");var r=0;C(function(){var t=Object(d.a)(u.a.mark((function t(n,a){var o;return u.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:o={value:n,lineNumbers:!0,lineWrapping:!0,theme:"monokai"},e.props.addShaderEditor(Object(i.jsx)("div",{className:S.a.shaderEditor,ref:function(e){if(e){var t=j(e,o);t.updatedSource=a;var n=e.firstElementChild,r=document.createElement("button");r.className=S.a.updateShaderBtn,r.innerHTML="Update shader",r.onclick=function(){return a(t.getValue())},n.prepend(r)}}},n+r++));case 2:case"end":return t.stop()}}),t)})));return function(e,n){return t.apply(this,arguments)}}()),this.canvasRef.current&&this.props.init(this.canvasRef.current,t).then((function(t){requestAnimationFrame((function n(r){e.stopRunning||(t(r),requestAnimationFrame(n))}))}))}},{key:"componentWillUnmount",value:function(){this.stopRunning=!0}},{key:"render",value:function(){var e=this.props,t=(e.gui,e.init,e.addShaderEditor,s(e,["gui","init","addShaderEditor"]));return Object(i.jsx)("canvas",R(R({},t),{},{ref:this.canvasRef}))}}])&&f(t.prototype,r),a&&f(t,a),c}(w.a.Component);function E(e){return function(){var t=Object(y.useState)("undefined"!==typeof navigator&&!!navigator.gpu),n=t[0],r=t[1],a=function(){var t=Object(d.a)(u.a.mark((function t(n,a){return u.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.prev=0,t.next=3,e.init(n,a);case 3:return t.abrupt("return",t.sent);case 6:t.prev=6,t.t0=t.catch(0),console.error(t.t0),r(!1);case 10:case"end":return t.stop()}}),t,null,[[0,6]])})));return function(e,n){return t.apply(this,arguments)}}(),s=Object(y.useState)([]),c=s[0],p=s[1],f=Object(y.useMemo)((function(){return Object(i.jsx)("div",{ref:function(t){var n={value:e.source,readOnly:!0,lineNumbers:!0,lineWrapping:!0,theme:"monokai",mode:"text/typescript"};j(t,n)}})}),[]);return Object(i.jsxs)("main",{children:[Object(i.jsxs)(b.a,{children:[Object(i.jsx)("style",{dangerouslySetInnerHTML:{__html:"\n            .CodeMirror {\n              height: auto !important;\n              margin: 1em 0;\n            }\n\n            .CodeMirror-scroll {\n              height: auto !important;\n              overflow: visible !important;\n            }\n          "}}),Object(i.jsx)("title",{children:"".concat(e.name," - WebGPU Samples")}),Object(i.jsx)("meta",{name:"description",content:e.description})]}),Object(i.jsxs)("div",{children:[Object(i.jsx)("h1",{children:e.name}),Object(i.jsx)("a",{target:"_blank",rel:"noreferrer",href:"https://github.com/austinEng/webgpu-samples/tree/main/src/pages/samples/".concat(e.slug,".ts"),children:"See it on Github!"}),Object(i.jsx)("p",{children:e.description}),n?null:Object(i.jsxs)(i.Fragment,{children:[Object(i.jsx)("p",{children:"Is WebGPU enabled?"}),Object(i.jsxs)("p",{children:["WebGPU or this example is not supported! Please visit"," ",Object(i.jsx)("a",{href:"//webgpu.io",children:"webgpu.io"})," to see the current implementation status."]})]})]}),Object(i.jsx)("div",{className:S.a.canvasContainer,children:n?Object(i.jsx)(T,{init:a,gui:e.gui,addShaderEditor:function(e){return p([].concat(o(c),[e]))},width:O,height:V}):Object(i.jsx)("canvas",{width:O,height:V})}),Object(i.jsxs)("div",{children:[c,f]})]})}}},XAJ8:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/samples/reversedZ",function(){return n("7r7F")}])},a3WO:function(e,t,n){"use strict";function r(e,t){(null==t||t>e.length)&&(t=e.length);for(var n=0,r=new Array(t);n<t;n++)r[n]=e[n];return r}n.d(t,"a",(function(){return r}))}},[["XAJ8",0,1,4,2,3,6]]]);