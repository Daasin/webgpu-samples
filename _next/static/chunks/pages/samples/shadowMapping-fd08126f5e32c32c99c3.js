_N_E=(window.webpackJsonp_N_E=window.webpackJsonp_N_E||[]).push([[21],{DELu:function(e,n,t){"use strict";t.r(n);var r=t("o0o1"),a=t.n(r);var o=t("BsWD");function i(e,n){return function(e){if(Array.isArray(e))return e}(e)||function(e,n){if("undefined"!==typeof Symbol&&Symbol.iterator in Object(e)){var t=[],r=!0,a=!1,o=void 0;try{for(var i,s=e[Symbol.iterator]();!(r=(i=s.next()).done)&&(t.push(i.value),!n||t.length!==n);r=!0);}catch(c){a=!0,o=c}finally{try{r||null==s.return||s.return()}finally{if(a)throw o}}return t}}(e,n)||Object(o.a)(e,n)||function(){throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}var s=t("HaE+"),c=t("IOcx"),u=t("SoUo"),f=t("FvBH"),d=t.n(f),l={positions:d.a.positions,triangles:d.a.cells,normals:[]},m=1024;function p(){return(p=Object(s.a)(a.a.mark((function e(n){var t,r,o,s,u,f,d,p,g,v,x,w,b,P,y,M,S,E,B,V,T,U,G,F,A,R,D,L,_,j,C,N,O,z,I,k,Y,q,X,H,W,J,Z;return a.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:return J=function(){var e=c.b.fromValues(0,50,-100),n=Math.PI*(Date.now()/2e3);c.b.rotateY(e,e,_,n);var t=c.a.create();return c.a.lookAt(t,e,_,L),c.a.multiply(k,j,t),k},e.next=3,navigator.gpu.requestAdapter();case 3:return t=e.sent,e.next=6,t.requestDevice();case 6:for(r=e.sent,o=Math.abs(n.width/n.height),s=n.getContext("gpupresent"),u=s.configureSwapChain({device:r,format:"bgra8unorm"}),l.triangles.push([l.positions.length,l.positions.length+2,l.positions.length+1],[l.positions.length,l.positions.length+1,l.positions.length+3]),l.positions.push([-100,20,-100],[100,20,100],[-100,20,100],[100,20,-100]),l.normals=l.positions.map((function(){return[0,0,0]})),l.triangles.forEach((function(e){var n=i(e,3),t=n[0],r=n[1],a=n[2],o=l.positions[t],s=l.positions[r],u=l.positions[a],f=c.b.subtract(c.b.create(),s,o),d=c.b.subtract(c.b.create(),u,o);c.b.normalize(f,f),c.b.normalize(d,d);var m=c.b.cross(c.b.create(),f,d);c.b.add(l.normals[t],l.normals[t],m),c.b.add(l.normals[r],l.normals[r],m),c.b.add(l.normals[a],l.normals[a],m)})),l.normals.forEach((function(e){c.b.normalize(e,e)})),f=r.createBuffer({size:3*l.positions.length*2*Float32Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.VERTEX,mappedAtCreation:!0}),d=new Float32Array(f.getMappedRange()),p=0;p<l.positions.length;++p)d.set(l.positions[p],6*p),d.set(l.normals[p],6*p+3);for(f.unmap(),g=3*l.triangles.length,v=r.createBuffer({size:g*Uint16Array.BYTES_PER_ELEMENT,usage:GPUBufferUsage.INDEX,mappedAtCreation:!0}),x=new Uint16Array(v.getMappedRange()),w=0;w<l.triangles.length;++w)x.set(l.triangles[w],3*w);return v.unmap(),b=r.createTexture({size:[m,m,1],usage:GPUTextureUsage.RENDER_ATTACHMENT|GPUTextureUsage.SAMPLED,format:"depth32float"}),P=b.createView(),y=[{arrayStride:6*Float32Array.BYTES_PER_ELEMENT,attributes:[{shaderLocation:0,offset:0,format:"float32x3"},{shaderLocation:1,offset:3*Float32Array.BYTES_PER_ELEMENT,format:"float32x3"}]}],M={topology:"triangle-list",cullMode:"back"},S=r.createRenderPipeline({vertex:{module:r.createShaderModule({code:h.vertexShadow}),entryPoint:"main",buffers:y},fragment:{module:r.createShaderModule({code:h.fragmentShadow}),entryPoint:"main",targets:[]},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth32float"},primitive:M}),E=r.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,buffer:{type:"uniform"}},{binding:1,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,texture:{sampleType:"depth"}},{binding:2,visibility:GPUShaderStage.VERTEX|GPUShaderStage.FRAGMENT,sampler:{type:"comparison"}}]}),B=r.createRenderPipeline({layout:r.createPipelineLayout({bindGroupLayouts:[E,S.getBindGroupLayout(1)]}),vertex:{module:r.createShaderModule({code:h.vertex}),entryPoint:"main",buffers:y},fragment:{module:r.createShaderModule({code:h.fragment}),entryPoint:"main",targets:[{format:"bgra8unorm"}]},depthStencil:{depthWriteEnabled:!0,depthCompare:"less",format:"depth24plus-stencil8"},primitive:M}),V=r.createTexture({size:{width:n.width,height:n.height},format:"depth24plus-stencil8",usage:GPUTextureUsage.RENDER_ATTACHMENT}),T={colorAttachments:[{view:void 0,loadValue:{r:.5,g:.5,b:.5,a:1},storeOp:"store"}],depthStencilAttachment:{view:V.createView(),depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}},U=r.createBuffer({size:64,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),G=r.createBuffer({size:140,usage:GPUBufferUsage.UNIFORM|GPUBufferUsage.COPY_DST}),F=r.createBindGroup({layout:S.getBindGroupLayout(0),entries:[{binding:0,resource:{buffer:G}}]}),A=r.createBindGroup({layout:E,entries:[{binding:0,resource:{buffer:G}},{binding:1,resource:P},{binding:2,resource:r.createSampler({compare:"less"})}]}),R=r.createBindGroup({layout:S.getBindGroupLayout(1),entries:[{binding:0,resource:{buffer:U}}]}),D=c.b.fromValues(0,50,-100),L=c.b.fromValues(0,1,0),_=c.b.fromValues(0,0,0),j=c.a.create(),c.a.perspective(j,2*Math.PI/5,o,1,2e3),C=c.a.create(),c.a.lookAt(C,D,_,L),N=c.b.fromValues(50,100,-100),O=c.a.create(),c.a.lookAt(O,N,_,L),z=c.a.create(),-80,80,-80,80,-200,300,c.a.ortho(z,-80,80,-80,80,-200,300),I=c.a.create(),c.a.multiply(I,z,O),k=c.a.create(),c.a.multiply(k,j,C),Y=c.a.create(),c.a.translate(Y,Y,c.b.fromValues(0,-5,0)),c.a.translate(Y,Y,c.b.fromValues(0,-40,0)),q=I,r.queue.writeBuffer(G,0,q.buffer,q.byteOffset,q.byteLength),X=k,r.queue.writeBuffer(G,64,X.buffer,X.byteOffset,X.byteLength),H=N,r.queue.writeBuffer(G,128,H.buffer,H.byteOffset,H.byteLength),W=Y,r.queue.writeBuffer(U,0,W.buffer,W.byteOffset,W.byteLength),Z={colorAttachments:[],depthStencilAttachment:{view:P,depthLoadValue:1,depthStoreOp:"store",stencilLoadValue:0,stencilStoreOp:"store"}},e.abrupt("return",(function(){var e=J();r.queue.writeBuffer(G,64,e.buffer,e.byteOffset,e.byteLength),T.colorAttachments[0].view=u.getCurrentTexture().createView();var n=r.createCommandEncoder(),t=n.beginRenderPass(Z);t.setPipeline(S),t.setBindGroup(0,F),t.setBindGroup(1,R),t.setVertexBuffer(0,f),t.setIndexBuffer(v,"uint16"),t.drawIndexed(g),t.endPass();var a=n.beginRenderPass(T);a.setPipeline(B),a.setBindGroup(0,A),a.setBindGroup(1,R),a.setVertexBuffer(0,f),a.setIndexBuffer(v,"uint16"),a.drawIndexed(g),a.endPass(),r.queue.submit([n.finish()])}));case 73:case"end":return e.stop()}}),e)})))).apply(this,arguments)}var h={vertexShadow:"\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[block]] struct Model {\n  [[offset(0)]] modelMatrix : mat4x4<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(1), binding(0)]] var<uniform> model : Model;\n\n[[stage(vertex)]]\nfn main([[location(0)]] position : vec3<f32>)\n     -> [[builtin(position)]] vec4<f32> {\n  return scene.lightViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n}\n",fragmentShadow:"\n[[stage(fragment)]]\nfn main() {\n}\n",vertex:"\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[block]] struct Model {\n  [[offset(0)]] modelMatrix : mat4x4<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(1), binding(0)]] var<uniform> model : Model;\n\nstruct VertexOutput {\n  [[location(0)]] shadowPos : vec3<f32>;\n  [[location(1)]] fragPos : vec3<f32>;\n  [[location(2)]] fragNorm : vec3<f32>;\n\n  [[builtin(position)]] Position : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[location(0)]] position : vec3<f32>,\n        [[location(1)]] normal : vec3<f32>) -> VertexOutput {\n  var output : VertexOutput;\n\n  // XY is in (-1, 1) space, Z is in (0, 1) space\n  let posFromLight : vec4<f32> = scene.lightViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n\n  // Convert XY to (0, 1)\n  // Y is flipped because texture coords are Y-down.\n  output.shadowPos = vec3<f32>(\n    posFromLight.xy * vec2<f32>(0.5, -0.5) + vec2<f32>(0.5, 0.5),\n    posFromLight.z\n  );\n\n  output.Position = scene.cameraViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n  output.fragPos = output.Position.xyz;\n  output.fragNorm = normal;\n  return output;\n}\n",fragment:"\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(0), binding(1)]] var shadowMap: texture_depth_2d;\n[[group(0), binding(2)]] var shadowSampler: sampler_comparison;\n\nstruct FragmentInput {\n  [[location(0)]] shadowPos : vec3<f32>;\n  [[location(1)]] fragPos : vec3<f32>;\n  [[location(2)]] fragNorm : vec3<f32>;\n};\n\nlet albedo : vec3<f32> = vec3<f32>(0.9, 0.9, 0.9);\nlet ambientFactor : f32 = 0.2;\n\n[[stage(fragment)]]\nfn main(input : FragmentInput) -> [[location(0)]] vec4<f32> {\n  // Percentage-closer filtering. Sample texels in the region\n  // to smooth the result.\n  var shadowFactor : f32 = 0.0;\n  for (var y : i32 = -1 ; y <= 1 ; y = y + 1) {\n      for (var x : i32 = -1 ; x <= 1 ; x = x + 1) {\n        let offset : vec2<f32> = vec2<f32>(\n          f32(x) * ".concat(.0009765625,",\n          f32(y) * ").concat(.0009765625,");\n\n        shadowFactor = shadowFactor + textureSampleCompare(\n          shadowMap, shadowSampler,\n          input.shadowPos.xy + offset, input.shadowPos.z - 0.007);\n      }\n  }\n\n  shadowFactor = ambientFactor + shadowFactor / 9.0;\n\n  let lambertFactor : f32 = abs(dot(normalize(scene.lightPos - input.fragPos), input.fragNorm));\n\n  let lightingFactor : f32 = min(shadowFactor * lambertFactor, 1.0);\n  return vec4<f32>(lightingFactor * albedo, 1.0);\n}\n")};n.default=Object(u.c)({name:"Shadow Mapping",description:"This example shows how to sample from a depth texture to render shadows.",slug:"shadowMapping",init:function(e){return p.apply(this,arguments)},source:"import { mat4, vec3 } from 'gl-matrix';\nimport { makeBasicExample } from '../../components/basicExample';\n\nimport dragonRawData from 'stanford-dragon/4';\nconst mesh = {\n  positions: dragonRawData.positions as [number, number, number][],\n  triangles: dragonRawData.cells as [number, number, number][],\n  normals: [] as [number, number, number][],\n};\n\nconst shadowDepthTextureSize = 1024;\n\nasync function init(canvas: HTMLCanvasElement) {\n  const adapter = await navigator.gpu.requestAdapter();\n  const device = await adapter.requestDevice();\n\n  const aspect = Math.abs(canvas.width / canvas.height);\n\n  const context = canvas.getContext('gpupresent');\n\n  const swapChain = context.configureSwapChain({\n    device,\n    format: 'bgra8unorm',\n  });\n\n  // Push indices for an additional ground plane\n  mesh.triangles.push(\n    [\n      mesh.positions.length,\n      mesh.positions.length + 2,\n      mesh.positions.length + 1,\n    ],\n    [\n      mesh.positions.length,\n      mesh.positions.length + 1,\n      mesh.positions.length + 3,\n    ]\n  );\n\n  // Push positions for an additional ground plane\n  // prettier-ignore\n  mesh.positions.push(\n    [-100, 20, -100], //\n    [ 100, 20,  100], //\n    [-100, 20,  100], //\n    [ 100, 20, -100]\n  );\n\n  // Compute surface normals\n  mesh.normals = mesh.positions.map(() => {\n    // Initialize to zero.\n    return [0, 0, 0];\n  });\n  mesh.triangles.forEach(([i0, i1, i2]) => {\n    const p0 = mesh.positions[i0];\n    const p1 = mesh.positions[i1];\n    const p2 = mesh.positions[i2];\n\n    const v0 = vec3.subtract(vec3.create(), p1, p0);\n    const v1 = vec3.subtract(vec3.create(), p2, p0);\n\n    vec3.normalize(v0, v0);\n    vec3.normalize(v1, v1);\n    const norm = vec3.cross(vec3.create(), v0, v1);\n\n    // Accumulate the normals.\n    vec3.add(mesh.normals[i0], mesh.normals[i0], norm);\n    vec3.add(mesh.normals[i1], mesh.normals[i1], norm);\n    vec3.add(mesh.normals[i2], mesh.normals[i2], norm);\n  });\n  mesh.normals.forEach((n) => {\n    // Normalize accumulated normals.\n    vec3.normalize(n, n);\n  });\n\n  // Create the model vertex buffer.\n  const vertexBuffer = device.createBuffer({\n    size: mesh.positions.length * 3 * 2 * Float32Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.VERTEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Float32Array(vertexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.positions.length; ++i) {\n      mapping.set(mesh.positions[i], 6 * i);\n      mapping.set(mesh.normals[i], 6 * i + 3);\n    }\n    vertexBuffer.unmap();\n  }\n\n  // Create the model index buffer.\n  const indexCount = mesh.triangles.length * 3;\n  const indexBuffer = device.createBuffer({\n    size: indexCount * Uint16Array.BYTES_PER_ELEMENT,\n    usage: GPUBufferUsage.INDEX,\n    mappedAtCreation: true,\n  });\n  {\n    const mapping = new Uint16Array(indexBuffer.getMappedRange());\n    for (let i = 0; i < mesh.triangles.length; ++i) {\n      mapping.set(mesh.triangles[i], 3 * i);\n    }\n    indexBuffer.unmap();\n  }\n\n  // Create the depth texture for rendering/sampling the shadow map.\n  const shadowDepthTexture = device.createTexture({\n    size: [shadowDepthTextureSize, shadowDepthTextureSize, 1],\n    usage: GPUTextureUsage.RENDER_ATTACHMENT | GPUTextureUsage.SAMPLED,\n    format: 'depth32float',\n  });\n  const shadowDepthTextureView = shadowDepthTexture.createView();\n\n  // Create some common descriptors used for both the shadow pipeline\n  // and the color rendering pipeline.\n  const vertexBuffers: Iterable<GPUVertexBufferLayout> = [\n    {\n      arrayStride: Float32Array.BYTES_PER_ELEMENT * 6,\n      attributes: [\n        {\n          // position\n          shaderLocation: 0,\n          offset: 0,\n          format: 'float32x3',\n        },\n        {\n          // normal\n          shaderLocation: 1,\n          offset: Float32Array.BYTES_PER_ELEMENT * 3,\n          format: 'float32x3',\n        },\n      ],\n    },\n  ];\n\n  const primitive: GPUPrimitiveState = {\n    topology: 'triangle-list',\n    cullMode: 'back',\n  };\n\n  const shadowPipeline = device.createRenderPipeline({\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertexShadow,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    fragment: {\n      // This should be omitted and we can use a vertex-only pipeline, but it's\n      // not yet implemented.\n      module: device.createShaderModule({\n        code: wgslShaders.fragmentShadow,\n      }),\n      entryPoint: 'main',\n      targets: [],\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth32float',\n    },\n    primitive,\n  });\n\n  // Create a bind group layout which holds the scene uniforms and\n  // the texture+sampler for depth. We create it manually because the WebPU\n  // implementation doesn't infer this from the shader (yet).\n  const bglForRender = device.createBindGroupLayout({\n    entries: [\n      {\n        binding: 0,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        buffer: {\n          type: 'uniform',\n        },\n      },\n      {\n        binding: 1,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        texture: {\n          sampleType: 'depth',\n        },\n      },\n      {\n        binding: 2,\n        visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT,\n        sampler: {\n          type: 'comparison',\n        },\n      },\n    ],\n  });\n\n  const pipeline = device.createRenderPipeline({\n    // Specify the pipeline layout. The layout for the model is the same, so\n    // reuse it from the shadow pipeline.\n    layout: device.createPipelineLayout({\n      bindGroupLayouts: [bglForRender, shadowPipeline.getBindGroupLayout(1)],\n    }),\n    vertex: {\n      module: device.createShaderModule({\n        code: wgslShaders.vertex,\n      }),\n      entryPoint: 'main',\n      buffers: vertexBuffers,\n    },\n    fragment: {\n      module: device.createShaderModule({\n        code: wgslShaders.fragment,\n      }),\n      entryPoint: 'main',\n      targets: [\n        {\n          format: 'bgra8unorm',\n        },\n      ],\n    },\n    depthStencil: {\n      depthWriteEnabled: true,\n      depthCompare: 'less',\n      format: 'depth24plus-stencil8',\n    },\n    primitive,\n  });\n\n  const depthTexture = device.createTexture({\n    size: {\n      width: canvas.width,\n      height: canvas.height,\n    },\n    format: 'depth24plus-stencil8',\n    usage: GPUTextureUsage.RENDER_ATTACHMENT,\n  });\n\n  const renderPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [\n      {\n        // view is acquired and set in render loop.\n        view: undefined,\n\n        loadValue: { r: 0.5, g: 0.5, b: 0.5, a: 1.0 },\n        storeOp: 'store',\n      },\n    ],\n    depthStencilAttachment: {\n      view: depthTexture.createView(),\n\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0,\n      stencilStoreOp: 'store',\n    },\n  };\n\n  const modelUniformBuffer = device.createBuffer({\n    size: 4 * 16, // 4x4 matrix\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneUniformBuffer = device.createBuffer({\n    // Two 4x4 viewProj matrices,\n    // one for the camera and one for the light.\n    // Then a vec3 for the light position.\n    size: 2 * 4 * 16 + 3 * 4,\n    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,\n  });\n\n  const sceneBindGroupForShadow = device.createBindGroup({\n    layout: shadowPipeline.getBindGroupLayout(0),\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const sceneBindGroupForRender = device.createBindGroup({\n    layout: bglForRender,\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: sceneUniformBuffer,\n        },\n      },\n      {\n        binding: 1,\n        resource: shadowDepthTextureView,\n      },\n      {\n        binding: 2,\n        resource: device.createSampler({\n          compare: 'less',\n        }),\n      },\n    ],\n  });\n\n  const modelBindGroup = device.createBindGroup({\n    layout: shadowPipeline.getBindGroupLayout(1),\n    entries: [\n      {\n        binding: 0,\n        resource: {\n          buffer: modelUniformBuffer,\n        },\n      },\n    ],\n  });\n\n  const eyePosition = vec3.fromValues(0, 50, -100);\n  const upVector = vec3.fromValues(0, 1, 0);\n  const origin = vec3.fromValues(0, 0, 0);\n\n  const projectionMatrix = mat4.create();\n  mat4.perspective(projectionMatrix, (2 * Math.PI) / 5, aspect, 1, 2000.0);\n\n  const viewMatrix = mat4.create();\n  mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n  const lightPosition = vec3.fromValues(50, 100, -100);\n  const lightViewMatrix = mat4.create();\n  mat4.lookAt(lightViewMatrix, lightPosition, origin, upVector);\n\n  const lightProjectionMatrix = mat4.create();\n  {\n    const left = -80;\n    const right = 80;\n    const bottom = -80;\n    const top = 80;\n    const near = -200;\n    const far = 300;\n    mat4.ortho(lightProjectionMatrix, left, right, bottom, top, near, far);\n  }\n\n  const lightViewProjMatrix = mat4.create();\n  mat4.multiply(lightViewProjMatrix, lightProjectionMatrix, lightViewMatrix);\n\n  const viewProjMatrix = mat4.create();\n  mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n\n  // Move the model so it's centered.\n  const modelMatrix = mat4.create();\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -5, 0));\n  mat4.translate(modelMatrix, modelMatrix, vec3.fromValues(0, -40, 0));\n\n  // The camera/light aren't moving, so write them into buffers now.\n  {\n    const lightMatrixData = lightViewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      0,\n      lightMatrixData.buffer,\n      lightMatrixData.byteOffset,\n      lightMatrixData.byteLength\n    );\n\n    const cameraMatrixData = viewProjMatrix as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraMatrixData.buffer,\n      cameraMatrixData.byteOffset,\n      cameraMatrixData.byteLength\n    );\n\n    const lightData = lightPosition as Float32Array;\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      128,\n      lightData.buffer,\n      lightData.byteOffset,\n      lightData.byteLength\n    );\n\n    const modelData = modelMatrix as Float32Array;\n    device.queue.writeBuffer(\n      modelUniformBuffer,\n      0,\n      modelData.buffer,\n      modelData.byteOffset,\n      modelData.byteLength\n    );\n  }\n\n  // Rotates the camera around the origin based on time.\n  function getCameraViewProjMatrix() {\n    const eyePosition = vec3.fromValues(0, 50, -100);\n\n    const rad = Math.PI * (Date.now() / 2000);\n    vec3.rotateY(eyePosition, eyePosition, origin, rad);\n\n    const viewMatrix = mat4.create();\n    mat4.lookAt(viewMatrix, eyePosition, origin, upVector);\n\n    mat4.multiply(viewProjMatrix, projectionMatrix, viewMatrix);\n    return viewProjMatrix as Float32Array;\n  }\n\n  const shadowPassDescriptor: GPURenderPassDescriptor = {\n    colorAttachments: [],\n    depthStencilAttachment: {\n      view: shadowDepthTextureView,\n      depthLoadValue: 1.0,\n      depthStoreOp: 'store',\n      stencilLoadValue: 0,\n      stencilStoreOp: 'store',\n    },\n  };\n\n  return function frame() {\n    const cameraViewProj = getCameraViewProjMatrix();\n    device.queue.writeBuffer(\n      sceneUniformBuffer,\n      64,\n      cameraViewProj.buffer,\n      cameraViewProj.byteOffset,\n      cameraViewProj.byteLength\n    );\n\n    renderPassDescriptor.colorAttachments[0].view = swapChain\n      .getCurrentTexture()\n      .createView();\n\n    const commandEncoder = device.createCommandEncoder();\n    {\n      const shadowPass = commandEncoder.beginRenderPass(shadowPassDescriptor);\n      shadowPass.setPipeline(shadowPipeline);\n      shadowPass.setBindGroup(0, sceneBindGroupForShadow);\n      shadowPass.setBindGroup(1, modelBindGroup);\n      shadowPass.setVertexBuffer(0, vertexBuffer);\n      shadowPass.setIndexBuffer(indexBuffer, 'uint16');\n      shadowPass.drawIndexed(indexCount);\n\n      shadowPass.endPass();\n    }\n    {\n      const renderPass = commandEncoder.beginRenderPass(renderPassDescriptor);\n      renderPass.setPipeline(pipeline);\n      renderPass.setBindGroup(0, sceneBindGroupForRender);\n      renderPass.setBindGroup(1, modelBindGroup);\n      renderPass.setVertexBuffer(0, vertexBuffer);\n      renderPass.setIndexBuffer(indexBuffer, 'uint16');\n      renderPass.drawIndexed(indexCount);\n\n      renderPass.endPass();\n    }\n    device.queue.submit([commandEncoder.finish()]);\n  };\n}\n\nconst wgslShaders = {\n  vertexShadow: `\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[block]] struct Model {\n  [[offset(0)]] modelMatrix : mat4x4<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(1), binding(0)]] var<uniform> model : Model;\n\n[[stage(vertex)]]\nfn main([[location(0)]] position : vec3<f32>)\n     -> [[builtin(position)]] vec4<f32> {\n  return scene.lightViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n}\n`,\n\n  fragmentShadow: `\n[[stage(fragment)]]\nfn main() {\n}\n`,\n\n  vertex: `\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[block]] struct Model {\n  [[offset(0)]] modelMatrix : mat4x4<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(1), binding(0)]] var<uniform> model : Model;\n\nstruct VertexOutput {\n  [[location(0)]] shadowPos : vec3<f32>;\n  [[location(1)]] fragPos : vec3<f32>;\n  [[location(2)]] fragNorm : vec3<f32>;\n\n  [[builtin(position)]] Position : vec4<f32>;\n};\n\n[[stage(vertex)]]\nfn main([[location(0)]] position : vec3<f32>,\n        [[location(1)]] normal : vec3<f32>) -> VertexOutput {\n  var output : VertexOutput;\n\n  // XY is in (-1, 1) space, Z is in (0, 1) space\n  let posFromLight : vec4<f32> = scene.lightViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n\n  // Convert XY to (0, 1)\n  // Y is flipped because texture coords are Y-down.\n  output.shadowPos = vec3<f32>(\n    posFromLight.xy * vec2<f32>(0.5, -0.5) + vec2<f32>(0.5, 0.5),\n    posFromLight.z\n  );\n\n  output.Position = scene.cameraViewProjMatrix * model.modelMatrix * vec4<f32>(position, 1.0);\n  output.fragPos = output.Position.xyz;\n  output.fragNorm = normal;\n  return output;\n}\n`,\n  fragment: `\n[[block]] struct Scene {\n  [[offset(0)]] lightViewProjMatrix : mat4x4<f32>;\n  [[offset(64)]] cameraViewProjMatrix : mat4x4<f32>;\n  [[offset(128)]] lightPos : vec3<f32>;\n};\n\n[[group(0), binding(0)]] var<uniform> scene : Scene;\n[[group(0), binding(1)]] var shadowMap: texture_depth_2d;\n[[group(0), binding(2)]] var shadowSampler: sampler_comparison;\n\nstruct FragmentInput {\n  [[location(0)]] shadowPos : vec3<f32>;\n  [[location(1)]] fragPos : vec3<f32>;\n  [[location(2)]] fragNorm : vec3<f32>;\n};\n\nlet albedo : vec3<f32> = vec3<f32>(0.9, 0.9, 0.9);\nlet ambientFactor : f32 = 0.2;\n\n[[stage(fragment)]]\nfn main(input : FragmentInput) -> [[location(0)]] vec4<f32> {\n  // Percentage-closer filtering. Sample texels in the region\n  // to smooth the result.\n  var shadowFactor : f32 = 0.0;\n  for (var y : i32 = -1 ; y <= 1 ; y = y + 1) {\n      for (var x : i32 = -1 ; x <= 1 ; x = x + 1) {\n        let offset : vec2<f32> = vec2<f32>(\n          f32(x) * ${1 / shadowDepthTextureSize},\n          f32(y) * ${1 / shadowDepthTextureSize});\n\n        shadowFactor = shadowFactor + textureSampleCompare(\n          shadowMap, shadowSampler,\n          input.shadowPos.xy + offset, input.shadowPos.z - 0.007);\n      }\n  }\n\n  shadowFactor = ambientFactor + shadowFactor / 9.0;\n\n  let lambertFactor : f32 = abs(dot(normalize(scene.lightPos - input.fragPos), input.fragNorm));\n\n  let lightingFactor : f32 = min(shadowFactor * lambertFactor, 1.0);\n  return vec4<f32>(lightingFactor * albedo, 1.0);\n}\n`,\n};\n\nexport default makeBasicExample({\n  name: 'Shadow Mapping',\n  description:\n    'This example shows how to sample from a depth texture to render shadows.',\n  slug: 'shadowMapping',\n  init,\n  source: __SOURCE__,\n});\n"})},"N/8h":function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/samples/shadowMapping",function(){return t("DELu")}])}},[["N/8h",0,1,4,7,2,3,5]]]);